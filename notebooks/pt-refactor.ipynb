{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from geoimages import etl\n",
    "#from geoimages import neural\n",
    "#from keras.utils import plot_model\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1L(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Conv1L(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Conv1L, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(7,7),\n",
    "                               stride=1,padding=3, padding_mode='zeros')\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        #self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=320, out_features=50)\n",
    "        self.dense1_bn = nn.BatchNorm1d(50)\n",
    "        self.dense2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "conv1l = Conv1L()\n",
    "print(conv1l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape: (20998, 28, 28, 3)\n",
      "Y Train shape: (20998,)\n"
     ]
    }
   ],
   "source": [
    "## read training data, normalize X, One-hot Y\n",
    "labels = etl.Labels()\n",
    "hf = h5py.File('../datasets/image_classification_train.h5', 'r')\n",
    "X_Train_Orig = np.array(hf.get('X_Train_Orig'))\n",
    "Y_Train_Orig = np.array(hf.get('Y_Train_Orig'))\n",
    "X_Train = X_Train_Orig/255.\n",
    "Y_Train_OH = labels.categorical_to_onehot(Y_Train_Orig)\n",
    "hf.close()\n",
    "print('X Train shape: ' + str(X_Train_Orig.shape))\n",
    "print('Y Train shape: ' + str(Y_Train_Orig.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test shape: (3564, 28, 28, 3)\n",
      "Y Test shape: (3564,)\n"
     ]
    }
   ],
   "source": [
    "## read test data, normalize X, One-hot Y\n",
    "hf = h5py.File('../datasets/image_classification_test.h5', 'r')\n",
    "X_Test_Orig = np.array(hf.get('X_Test_Orig'))\n",
    "Y_Test_Orig = np.array(hf.get('Y_Test_Orig'))\n",
    "X_Test = X_Test_Orig/255.\n",
    "Y_Test_OH = labels.categorical_to_onehot(Y_Test_Orig)\n",
    "hf.close()\n",
    "print('X Test shape: ' + str(X_Test_Orig.shape))\n",
    "print('Y Test shape: ' + str(Y_Test_Orig.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Layer Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1L\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 6)                 43206     \n",
      "=================================================================\n",
      "Total params: 44,230\n",
      "Trainable params: 44,166\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "20998/20998 [==============================] - 52s 2ms/step - loss: 0.4231 - accuracy: 0.8614\n",
      "Epoch 2/5\n",
      "20998/20998 [==============================] - 52s 2ms/step - loss: 0.2684 - accuracy: 0.9104\n",
      "Epoch 3/5\n",
      "20998/20998 [==============================] - 52s 2ms/step - loss: 0.2122 - accuracy: 0.9294\n",
      "Epoch 4/5\n",
      "20998/20998 [==============================] - 51s 2ms/step - loss: 0.1800 - accuracy: 0.9375\n",
      "Epoch 5/5\n",
      "20998/20998 [==============================] - 53s 3ms/step - loss: 0.1727 - accuracy: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa0f481d790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create, compile, train model\n",
    "model_1L = neural.Convolutional.Conv1L(X_Train.shape[1:])\n",
    "model_1L.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_1L.summary()\n",
    "plot_model(model_1L, to_file='./assets/Conv1L.png')\n",
    "model_1L.fit(x=X_Train, y=Y_Train_OH, batch_size=16, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3564/3564 [==============================] - 4s 986us/step\n",
      "\n",
      "Loss = 0.4817236965035081\n",
      "Test Accuracy = 0.8751403093338013\n"
     ]
    }
   ],
   "source": [
    "## evaluate test set\n",
    "preds_1L = model_1L.evaluate(x=X_Test, y=Y_Test_OH)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_1L[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_1L[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "model_1L.save('../models/model_1L.h5', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Layer Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv2L\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 6)                 13830     \n",
      "=================================================================\n",
      "Total params: 33,606\n",
      "Trainable params: 33,414\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "20998/20998 [==============================] - 79s 4ms/step - loss: 0.3554 - accuracy: 0.8679\n",
      "Epoch 2/5\n",
      "20998/20998 [==============================] - 79s 4ms/step - loss: 0.2126 - accuracy: 0.9230\n",
      "Epoch 3/5\n",
      "20998/20998 [==============================] - 78s 4ms/step - loss: 0.1730 - accuracy: 0.9376\n",
      "Epoch 4/5\n",
      "20998/20998 [==============================] - 78s 4ms/step - loss: 0.1445 - accuracy: 0.9470\n",
      "Epoch 5/5\n",
      "20998/20998 [==============================] - 80s 4ms/step - loss: 0.1388 - accuracy: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa14c4a6190>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create, compile, fit model\n",
    "model_2L = neural.Convolutional.Conv2L(X_Train.shape[1:])\n",
    "model_2L.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_2L.summary()\n",
    "plot_model(model_2L, to_file='./assets/Conv2L.png')\n",
    "model_2L.fit(x=X_Train, y=Y_Train_OH, batch_size=16, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3564/3564 [==============================] - 4s 1ms/step\n",
      "\n",
      "Loss = 0.11371453629867262\n",
      "Test Accuracy = 0.9635241031646729\n"
     ]
    }
   ],
   "source": [
    "## evaluate test set\n",
    "preds_2L = model_2L.evaluate(x=X_Test, y=Y_Test_OH)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_2L[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_2L[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "model_2L.save('../models/model_2L.h5', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"smallVGGNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 6)                 6150      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 814,982\n",
      "Trainable params: 812,102\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "20998/20998 [==============================] - 114s 5ms/step - loss: 0.5373 - accuracy: 0.8325\n",
      "Epoch 2/5\n",
      "20998/20998 [==============================] - 109s 5ms/step - loss: 0.3233 - accuracy: 0.8909\n",
      "Epoch 3/5\n",
      "20998/20998 [==============================] - 109s 5ms/step - loss: 0.2731 - accuracy: 0.9097\n",
      "Epoch 4/5\n",
      "20998/20998 [==============================] - 110s 5ms/step - loss: 0.2539 - accuracy: 0.9179\n",
      "Epoch 5/5\n",
      "20998/20998 [==============================] - 110s 5ms/step - loss: 0.2106 - accuracy: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa0a2d14c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create, compile, fit model\n",
    "model_VGG = neural.Convolutional.smallVGGNet(X_Train.shape[1:])\n",
    "model_VGG.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_VGG.summary()\n",
    "plot_model(model_VGG, to_file='./assets/VGG.png')\n",
    "model_VGG.fit(x=X_Train, y=Y_Train_OH, batch_size=16, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3564/3564 [==============================] - 5s 2ms/step\n",
      "\n",
      "Loss = 1.0302366168812067\n",
      "Test Accuracy = 0.7314814925193787\n"
     ]
    }
   ],
   "source": [
    "## evaluate test set\n",
    "preds_VGG = model_VGG.evaluate(x=X_Test, y=Y_Test_OH)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_VGG[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_VGG[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "model_VGG.save('../models/model_VGG.h5', include_optimizer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
